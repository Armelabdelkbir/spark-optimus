# ğŸš€ Spark Configuration Analyzer - Agent-Based Evaluation System

An intelligent system that analyzes Apache Spark configurations from Git repositories and correlates them with real-time execution data from the Spark History Server. Built as an MCP (Model Context Protocol) server for seamless AI agent integration.

## ğŸ¯ Features

- **ğŸ“„ Configuration Parsing**: Automatically parse `spark-defaults.conf` files and `spark-submit` scripts
- **ğŸ“Š Metrics Integration**: Fetch real-time execution data from Spark History Server REST API
- **ğŸ¤– AI-Powered Analysis**: Use OpenAI to generate intelligent recommendations
- **ğŸ” Rule-Based Validation**: Built-in heuristics for common Spark anti-patterns
- **ğŸ­ Demo Mode**: Works standalone with mock data for presentations
- **ğŸ”§ MCP Server**: Expose tools for AI agents to interact with Spark configurations

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Git Repository â”‚
â”‚  (Spark Configs)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Config Parser  â”‚      â”‚ History Server   â”‚
â”‚                 â”‚      â”‚  REST API        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   MCP Server   â”‚
         â”‚  (4 Tools)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   AI Agent     â”‚
         â”‚   (OpenAI)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Recommendationsâ”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- (Optional) Google AI API key for Gemini
- (Optional) Access to Spark History Server

### Installation

```bash
# Clone or navigate to the project
cd agent-spark

# Install uv if you don't have it
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install dependencies and setup environment
uv venv
source .venv/bin/activate
uv pip install -e .

# (Optional) Set up environment variables
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
```

### Run the Demo

```bash
# Run the standalone demo
uv run demo_agent.py
```

This will:
1. Parse the sample `deploy_job.sh` script
2. Parse the `spark-defaults.conf` file
3. Fetch mock execution metrics
4. Generate AI-powered recommendations

### Run as MCP Server

```bash
# Start the MCP server
uv run -m spark_config_mcp.server
```

The server exposes 4 tools for AI agents:
- `parse_spark_config` - Parse configuration files
- `fetch_app_metrics` - Get execution metrics
- `analyze_configuration` - Full analysis with OpenAI
- `get_recommendations` - Filtered recommendations

## ğŸ“š MCP Tools Documentation

### 1. parse_spark_config

Parse Spark configuration files from a repository or file.

**Input:**
```json
{
  "path": "/path/to/config/file",
  "file_type": "auto"  // auto, spark-defaults, spark-submit, directory
}
```

**Output:**
```json
{
  "success": true,
  "config": {
    "source_file": "deploy_job.sh",
    "driver_memory": "20g",
    "executor_memory": "8g",
    "executor_cores": 4,
    "num_executors": 10,
    ...
  }
}
```

### 2. fetch_app_metrics

Fetch execution metrics from Spark History Server.

**Input:**
```json
{
  "app_identifier": "app-20260126-001",  // or app name pattern
  "use_mock": true
}
```

**Output:**
```json
{
  "success": true,
  "metrics": {
    "app_id": "app-20260126-001",
    "duration_ms": 1800000,
    "total_tasks": 500,
    "executor_memory_spilled": 5368709120,
    ...
  }
}
```

### 3. analyze_configuration

Perform comprehensive analysis with AI.

**Input:**
```json
{
  "config_path": "/path/to/config",
  "app_identifier": "Production_Pipeline",  // optional
  "use_mock_metrics": true
}
```

**Output:**
```json
{
  "success": true,
  "analysis": {
    "summary": "Configuration has critical issues...",
    "recommendations": [
      {
        "severity": "critical",
        "category": "resource_allocation",
        "title": "Excessive Driver Memory",
        "current_value": "20g",
        "recommended_value": "4g",
        "expected_impact": "Reduce costs by 75%"
      }
    ]
  }
}
```

### 4. get_recommendations

Get filtered, prioritized recommendations.

**Input:**
```json
{
  "config_path": "/path/to/config",
  "severity_filter": "critical",  // all, critical, warning, info
  "category_filter": "all"  // all, resource_allocation, performance_tuning, etc.
}
```

## ğŸ¯ Use Cases

### Hackathon Demo

Perfect for demonstrating:
- âœ… Works without real Spark cluster
- âœ… Mock data included
- âœ… Instant analysis results
- âœ… Visual recommendations

### Real-World Integration

Connect to production systems:
1. Set `SPARK_HISTORY_SERVER_URL` to your History Server
2. Set `USE_MOCK_DATA=false`
3. Point to your Git repository with Spark configs
4. Get real-time recommendations

### CI/CD Integration

Add to your pipeline:
```bash
# Analyze configs before deployment
python -c "
from spark_config_mcp.spark_config_parser import SparkConfigParser
from spark_config_mcp.config_analyzer import ConfigAnalyzer

parser = SparkConfigParser()
analyzer = ConfigAnalyzer()

config = parser.parse_file('deploy_job.sh')
analysis = analyzer.analyze(config)

critical = [r for r in analysis.recommendations if r.severity.value == 'critical']
if critical:
    print('CRITICAL ISSUES FOUND!')
    exit(1)
"
# Start the AWS Community MCP for Spark
uv run -m mcp_apache_spark_history_server
```

## ğŸ“ Project Structure

```
agent-spark/
â”œâ”€â”€ spark_config_mcp/          # Main package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ server.py              # MCP server
â”‚   â”œâ”€â”€ models.py              # Data models
â”‚   â”œâ”€â”€ spark_config_parser.py # Config parser
â”‚   â”œâ”€â”€ history_server_client.py # API client
â”‚   â””â”€â”€ config_analyzer.py     # AI analyzer
â”œâ”€â”€ demo_repo/                 # Sample configs
â”‚   â”œâ”€â”€ deploy_job.sh          # Spark-submit script
â”‚   â””â”€â”€ spark-defaults.conf    # Config file
â”œâ”€â”€ mock_data/                 # Demo data
â”‚   â””â”€â”€ history_server_response.json
â”œâ”€â”€ demo_agent.py              # Standalone demo
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

### Environment Variables

- `OPENAI_API_KEY` - OpenAI API key (optional, enables AI analysis)
- `SPARK_HISTORY_SERVER_URL` - History Server URL (default: `http://localhost:18080`)
- `USE_MOCK_DATA` - Use mock data (default: `true`)

## ğŸ¨ Example Output

```
ğŸ”´ CRITICAL ISSUES:

   Excessive Driver Memory
   Category: resource_allocation
   Current: 20g
   Recommended: 4g
   Impact: Reduce resource waste and costs by 75%

âš ï¸  WARNINGS:

   Inefficient Shuffle Partitions
   Category: performance_tuning
   Current: 200
   Recommended: 50-100
   Impact: Reduce shuffle overhead by 30-40%

ğŸ’¡ SUGGESTIONS:

   Enable Dynamic Allocation
   Category: best_practices
   Current: false
   Recommended: true
   Impact: Better resource utilization and cost savings
```

## ğŸ¤ Contributing

This is a hackathon project! Feel free to:
- Add more rule-based checks
- Improve AI prompts
- Add support for more config formats
- Enhance the demo

## ğŸ“ License

MIT License - feel free to use for your hackathon or production!

## ğŸ“ Hackathon Tips

### Presentation Points

1. **Problem**: Spark configs are complex, often misconfigured, wasting resources
2. **Solution**: AI-powered analysis that correlates configs with actual performance
3. **Innovation**: MCP server enables any AI agent to analyze Spark configs
4. **Impact**: Reduce cloud costs, improve performance, prevent issues

### Demo Flow

1. Show the bad config (`deploy_job.sh` with 20GB driver memory)
2. Run the analyzer
3. Show critical recommendations
4. Explain the cost/performance impact
5. (Bonus) Show MCP server integration with AI agent

### Key Differentiators

- âœ… **Agent-based**: Works with any AI agent via MCP
- âœ… **Correlation**: Links configs to actual execution metrics
- âœ… **Actionable**: Specific recommendations, not just warnings
- âœ… **Production-ready**: Works with real History Server
- âœ… **Demo-friendly**: Mock data for presentations

## ğŸš€ Next Steps

1. **Add more parsers**: Support for Databricks notebooks, EMR configs
2. **Historical analysis**: Track config changes over time
3. **Cost estimation**: Calculate actual $ savings
4. **Auto-fix**: Generate optimized configs automatically
5. **Dashboard**: Web UI for visualization

---

**Built for hackathons, ready for production!** ğŸ‰
